[
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Setup",
    "section": "",
    "text": "Follow instructions from official page: https://nbdev.fast.ai/tutorials/tutorial.html. This tutorial includes the following installations:\n\nInstall JupyterLab (using pip or conda)\n\nInstall nbdev (using pip or conda)\n\nInstall Quarto (using command from nbdev)\n\nInstall Quarto JupyterLab extension (command pip install jupyterlab-quarto)\n\nNOTE\nIt is possible that you encounter errors due to latest updates from Jupyter Lab. One such error is JavaScript error when rendering notebook caused when adding comments onto parameter declaration. One solution to this is to downgrade Jupyter Lab version to 3, e.g.,\nconda install -c conda-forge jupyterlab=3",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#step-0---install-nbdev",
    "href": "setup.html#step-0---install-nbdev",
    "title": "Setup",
    "section": "",
    "text": "Follow instructions from official page: https://nbdev.fast.ai/tutorials/tutorial.html. This tutorial includes the following installations:\n\nInstall JupyterLab (using pip or conda)\n\nInstall nbdev (using pip or conda)\n\nInstall Quarto (using command from nbdev)\n\nInstall Quarto JupyterLab extension (command pip install jupyterlab-quarto)\n\nNOTE\nIt is possible that you encounter errors due to latest updates from Jupyter Lab. One such error is JavaScript error when rendering notebook caused when adding comments onto parameter declaration. One solution to this is to downgrade Jupyter Lab version to 3, e.g.,\nconda install -c conda-forge jupyterlab=3",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#step-1---initialize-repository",
    "href": "setup.html#step-1---initialize-repository",
    "title": "Setup",
    "section": "Step 1 - Initialize repository",
    "text": "Step 1 - Initialize repository\nFollow the First steps Section of the same tutorial. The main steps are:\n\nCreate and clone a new Github repository\n\nUse command nbdev_new in the cloned repository to initialize a nbdev project\n\nFollow the prompts to create a suitable setting.ini file\n\nNOTE\n\nBy default, the module automatically exported by nbdev will have the same name as the repository (if not set otherwise). The exported python files will be stored in a directory with the same name in root repository. Please be careful not to include inappropriate characters in the module name or source package, else the exported modules cannot be imported correctly.\n\nBy default, two Github actions are added after initialization - one for testing, and one for deploying automatically generated documents. However, for us it is better to remove the deploying actions (or writing new action just for generating documents). This is because deployiment is to ninjalabo.github.io by Github Pages, which is already occupied with our Landing Page.\n\nBy default, Apache LICENSE is added. But we can remove that file if repository is only for private use.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "setup.html#step-2---start-making-edits",
    "href": "setup.html#step-2---start-making-edits",
    "title": "Setup",
    "section": "Step 2 - Start making edits",
    "text": "Step 2 - Start making edits\nKeep following the tutorial. From its Recap section:\n\nInstall hooks for git-friendly notebooks with nbdev_install_hooks\n\nInstall your package for development with pip install -e '.[dev]' (automatic update)\n\nPreview your docs with nbdev_preview (generate Quarto pages for documentation)\n\nAdd your changes\n\nUpdate nbs/index.ipynb with your own information (this becomes the README.md file)\n\nPrepare your changes with nbdev_prepare\n\nPush to GitHub\n\nFor making changes, take a look at the example workflow in 02_workflow.ipynb.",
    "crumbs": [
      "Setup"
    ]
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "This workflow builds upon the process of developing a model for differentiating between pictures of cats and dogs. The source code and documentation is from https://docs.fast.ai/tutorial.vision.html.\nWe can use nbdev to seamlessly generate Python module and documentation from your experimental notebook. From this point onwards, all section represents one step, i.e., a newly modified version or an addition to your notebook from the previous step.",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "workflow.html#step-1---experimental-notebook",
    "href": "workflow.html#step-1---experimental-notebook",
    "title": "Workflow",
    "section": "Step 1 - Experimental Notebook",
    "text": "Step 1 - Experimental Notebook\nAt this stage, the notebook is mostly for experimenting with ideas and code. The notebook itself can just be as following:\n\nInstall fastai library\nDownload PETS dataset which include images of cats and dogs\nConstruct dataloader from dataset\nFine-tune pretrained model\n\n\nNotebook Content\n\n!pip install fastai\n\nRequirement already satisfied: fastai in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (2.7.17)\nRequirement already satisfied: pip in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (24.2)\nRequirement already satisfied: packaging in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (24.1)\nRequirement already satisfied: fastdownload&lt;2,&gt;=0.0.5 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (0.0.7)\nRequirement already satisfied: fastcore&lt;1.8,&gt;=1.5.29 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (1.7.16)\nRequirement already satisfied: torchvision&gt;=0.11 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (0.19.1)\nRequirement already satisfied: matplotlib in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (3.9.2)\nRequirement already satisfied: pandas in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (2.2.3)\nRequirement already satisfied: requests in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (2.32.3)\nRequirement already satisfied: pyyaml in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (6.0.2)\nRequirement already satisfied: fastprogress&gt;=0.2.4 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (1.0.3)\nRequirement already satisfied: pillow&gt;=9.0.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (11.0.0)\nRequirement already satisfied: scikit-learn in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (1.5.2)\nRequirement already satisfied: scipy in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (1.14.1)\nRequirement already satisfied: spacy&lt;4 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (3.8.2)\nRequirement already satisfied: torch&lt;2.5,&gt;=1.10 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from fastai) (2.4.1)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.11 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (3.0.12)\nRequirement already satisfied: spacy-loggers&lt;2.0.0,&gt;=1.0.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (1.0.5)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (1.0.10)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (2.0.8)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (3.0.9)\nRequirement already satisfied: thinc&lt;8.4.0,&gt;=8.3.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (8.3.2)\nRequirement already satisfied: wasabi&lt;1.2.0,&gt;=0.9.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (1.1.3)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.3 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (2.4.8)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (2.0.10)\nRequirement already satisfied: weasel&lt;0.5.0,&gt;=0.1.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (0.4.1)\nRequirement already satisfied: typer&lt;1.0.0,&gt;=0.3.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (0.12.5)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (4.66.5)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (2.9.2)\nRequirement already satisfied: jinja2 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (3.1.4)\nRequirement already satisfied: setuptools in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (75.1.0)\nRequirement already satisfied: langcodes&lt;4.0.0,&gt;=3.2.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (3.4.1)\nRequirement already satisfied: numpy&gt;=1.19.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from spacy&lt;4-&gt;fastai) (2.0.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from requests-&gt;fastai) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from requests-&gt;fastai) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from requests-&gt;fastai) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from requests-&gt;fastai) (2024.8.30)\nRequirement already satisfied: filelock in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (3.16.1)\nRequirement already satisfied: typing-extensions&gt;=4.8.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (4.12.2)\nRequirement already satisfied: sympy in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (1.13.3)\nRequirement already satisfied: networkx in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (3.4.1)\nRequirement already satisfied: fsspec in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (2024.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.1.105)\nRequirement already satisfied: triton==3.0.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from torch&lt;2.5,&gt;=1.10-&gt;fastai) (3.0.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&lt;2.5,&gt;=1.10-&gt;fastai) (12.6.77)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (1.3.0)\nRequirement already satisfied: cycler&gt;=0.10 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (4.54.1)\nRequirement already satisfied: kiwisolver&gt;=1.3.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (1.4.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (3.2.0)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from matplotlib-&gt;fastai) (2.9.0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from pandas-&gt;fastai) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from pandas-&gt;fastai) (2024.2)\nRequirement already satisfied: joblib&gt;=1.2.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from scikit-learn-&gt;fastai) (1.4.2)\nRequirement already satisfied: threadpoolctl&gt;=3.1.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from scikit-learn-&gt;fastai) (3.5.0)\nRequirement already satisfied: language-data&gt;=1.2 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;4-&gt;fastai) (1.2.0)\nRequirement already satisfied: annotated-types&gt;=0.6.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;4-&gt;fastai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,&lt;3.0.0,&gt;=1.7.4-&gt;spacy&lt;4-&gt;fastai) (2.23.4)\nRequirement already satisfied: six&gt;=1.5 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;fastai) (1.16.0)\nRequirement already satisfied: blis&lt;1.1.0,&gt;=1.0.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from thinc&lt;8.4.0,&gt;=8.3.0-&gt;spacy&lt;4-&gt;fastai) (1.0.1)\nRequirement already satisfied: confection&lt;1.0.0,&gt;=0.0.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from thinc&lt;8.4.0,&gt;=8.3.0-&gt;spacy&lt;4-&gt;fastai) (0.1.5)\nRequirement already satisfied: click&gt;=8.0.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (8.1.7)\nRequirement already satisfied: shellingham&gt;=1.3.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (1.5.4)\nRequirement already satisfied: rich&gt;=10.11.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (13.9.2)\nRequirement already satisfied: cloudpathlib&lt;1.0.0,&gt;=0.7.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (0.19.0)\nRequirement already satisfied: smart-open&lt;8.0.0,&gt;=5.2.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (7.0.5)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from jinja2-&gt;spacy&lt;4-&gt;fastai) (3.0.1)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from sympy-&gt;torch&lt;2.5,&gt;=1.10-&gt;fastai) (1.3.0)\nRequirement already satisfied: marisa-trie&gt;=0.7.7 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from language-data&gt;=1.2-&gt;langcodes&lt;4.0.0,&gt;=3.2.0-&gt;spacy&lt;4-&gt;fastai) (1.2.1)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (2.18.0)\nRequirement already satisfied: wrapt in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from smart-open&lt;8.0.0,&gt;=5.2.1-&gt;weasel&lt;0.5.0,&gt;=0.1.0-&gt;spacy&lt;4-&gt;fastai) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /home/nghivo/miniconda3/envs/nbdev-test/lib/python3.12/site-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&gt;=10.11.0-&gt;typer&lt;1.0.0,&gt;=0.3.0-&gt;spacy&lt;4-&gt;fastai) (0.1.2)\n\n\n\n# Import from fastai\nfrom fastai.vision.all import *\n\n\n# Download PETS dataset\npath = untar_data(URLs.PETS)\npath.ls()\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 01:10&lt;00:00]\n    \n    \n\n\n(#2) [Path('/home/nghivo/.fastai/data/oxford-iiit-pet/images'),Path('/home/nghivo/.fastai/data/oxford-iiit-pet/annotations')]\n\n\n\n# Extract images\nfiles = get_image_files(path/\"images\")\nlen(files)\n\n7390\n\n\n\n# Create dataset loader\ndef label_func(f): return f[0].isupper()\ndls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n# Fine-tune model from pretrained\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)\n\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /home/nghivo/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████████████████████████████████████████████████████████████████████████| 83.3M/83.3M [00:07&lt;00:00, 11.6MB/s]\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.150972\n0.024604\n0.008796\n00:22\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.057303\n0.012587\n0.005413\n00:28\n\n\n\n\n\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Predict a single image\nlearn.predict(files[0])\n\n\n\n\n\n\n\n\n('False', tensor(0), tensor([1.0000e+00, 9.0949e-08]))",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "workflow.html#step-2---refine-modularize-code",
    "href": "workflow.html#step-2---refine-modularize-code",
    "title": "Workflow",
    "section": "Step 2 - Refine & Modularize Code",
    "text": "Step 2 - Refine & Modularize Code\nAt this stage, suppose the developer wants to create a function that generates a predictor for single image classification between cats and dogs. The notebook now mostly involves modularizing the existing code into reusable functions, including the following:\n\nClass for Cat/Dog image classifier\nFunction for generating from pretrained model\nFunction for predicting a single image\n\nUse case with test\n\nNOTE\nIn this workflow, OOP (Object-Oriented Programming) is used for modularizing the code. However,it is entirely possible that we use functional programming instead. It is also possible that we skip this step and export this script as it is.\n\nNotebook Content\n\nExperimental notebook…\n\n\nModule\n\n# Import from fastai\nfrom fastai.vision.all import *\n\n\n# Original code from https://docs.fast.ai/examples/app_examples.html\n# Class for Cat/Dog image\nclass CatOrDogImageClassifier:\n    \"Classifier between cat and dog images\"\n    \n    def __init__(\n        self,\n        arch=resnet34,  # Pretrained model architecture\n        metrics=error_rate,  # Metrics to be used\n    ):\n        \"Generate classifier from pretrained model\"\n    \n        # Form dataset loader\n        set_seed(99, True)\n        path = untar_data(URLs.PETS)/'images'\n        dls = ImageDataLoaders.from_name_func(\n            path, get_image_files(path), valid_pct=0.2,\n            label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))\n\n        # Create and fine-tune learner\n        learner = vision_learner(dls, arch, metrics=metrics).to_fp16()\n        learner.fine_tune(1)\n        self.learner = learner\n        \n    def predict(self, file_path: str):\n        \"Predict a single image with the learner\"\n\n        # Extract prediction with learner\n        img = PILImage.create(file_path)\n        prediction = self.learner.predict(img)\n        label = 'Cat' if prediction[0]=='True' else 'Dog'\n        dog_prob = prediction[2][0].item()\n        cat_prob = prediction[2][1].item()\n        \n        # Print the results\n        print(f\"The animal in this picture is: {label}\")\n        print(f\"Probability of 'Dog': {dog_prob:.6f}\")\n        print(f\"Probability of 'Cat': {cat_prob:.6f}\")\n        \n        # Return the results\n        return label, dog_prob, cat_prob\n\n\n# Use case\nclassifer = CatOrDogImageClassifier()\nlabel, dog_prob, cat_prob = classifer.predict(\"images/cat.jpg\")\n\n# Image should be predicted as 'Cat'\nassert label=='Cat'\nassert cat_prob &gt; 0.5\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.147156\n0.022813\n0.008119\n00:16\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.051962\n0.031823\n0.011502\n00:20\n\n\n\n\n\n\n\n\n\n\n\n\nThe animal in this picture is: Cat\nProbability of 'Dog': 0.000073\nProbability of 'Cat': 0.999927",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "workflow.html#step-3---export-module",
    "href": "workflow.html#step-3---export-module",
    "title": "Workflow",
    "section": "Step 3 - Export Module",
    "text": "Step 3 - Export Module\nAt this stage, the developer needs to export these functions for future usage. nbdev provides an easy option for turning the written code in Jupyter Notebook into installable Python module. The export will involve multiple files, including the previous notebook. The changes to be made are as follows:\n\nAdd all external libraries to setting.ini\n\nAdd #| default_exp &lt;name&gt; to notebook to export into a new file with similar name\nAdd #| export to all relevant cells in notebook\n\nUse nbdev_export in CLI or add Jupyter Notebook cell for exporting with nbdev.nbdev_export()\n\nCheck the exported module\nInstall exported module in developer mode with pip install -e '.[dev]' (if not already)\nUse the exported module with from nbdev_test.&lt;name&gt; import *\n\nNOTE\nIf encountering errors in importing the new module, try:\n- Running pip install -e . again\n- Restarting Jupyter notebook or Python kernel\n- Running nbdev_prepare in CLI\n\nChange in setting.ini\nAll external libraries are to be added into the setting.ini file. In this workflow, we are only using fastai library version 2.7.17. To set this requirement in setting.ini, we need to add a line for requirement (or uncommenting the default requirement line):\n### Optional ###\nrequirements = fastai\nIf we want to specify version (recommended to avoid future compatibility issues), we can set this to:\nrequirements = fastai==2.7.17\nor\nrequirements = fastai&gt;=2.7.17\nIf there are new libraries, add them to the same line, separated by ‘’. For example:\nrequirements = fastai pandas\n\n\nNotebook Content\n\nExperimental notebook…\n\n\nModule\n\nsource\n\n\n\nCatOrDogImageClassifier\n\n CatOrDogImageClassifier (arch=&lt;function resnet34&gt;, metrics=&lt;function\n                          error_rate&gt;)\n\nClassifier between cat and dog images\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\narch\nfunction\nresnet34\nPretrained model architecture\n\n\nmetrics\nfunction\nerror_rate\nMetrics to be used\n\n\n\n\n# NOTE: it is not required to export this use case with test.\n# Use case\nclassifer = CatOrDogImageClassifier()\nlabel, dog_prob, cat_prob = classifer.predict(\"images/cat.jpg\")\n\n# Image should be predicted as 'Cat'\nassert label=='Cat'\nassert cat_prob &gt; 0.5\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.147156\n0.022813\n0.008119\n00:13\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.051962\n0.031823\n0.011502\n00:17\n\n\n\n\n\n\n\n\n\n\n\n\nThe animal in this picture is: Cat\nProbability of 'Dog': 0.000073\nProbability of 'Cat': 0.999927\n\n\n\n# Export via cell\nfrom nbdev import nbdev_export\nnbdev_export()\n\n\n\nChange in nbdev_test module\nAfter running the previous notebook, there should be a new file named classifier.py in the nbdev_test directory. This new file should include all code from cells with the #| export marker.",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "workflow.html#step-4---create-documentation",
    "href": "workflow.html#step-4---create-documentation",
    "title": "Workflow",
    "section": "Step 4 - Create Documentation",
    "text": "Step 4 - Create Documentation\nAt this stage, the developer wants to generate a full documentation of all this process. nbdev simplifies this process with nbdev_preview which generates Quarto Pages for documentation from the notebook. We need to prepare the notebook for documentation generation which should include:\n\nAdd narration with markdown cell\n\nAdd directives to cells to determine which cell is visible:\n\nAdd #| export for adding the cell to the module & documentation\n\nAdd #| hide for testing cells and nbdev operations cells\n\nFor more options, check out the official documents: https://nbdev.fast.ai/explanations/directives.html\n\n\nUse show_doc for displaying class / functions\nUse nbdev_preview for previewing documentation\nUse nbdev_docs for generating documentation in .html format\n\nNOTE\nAfter this running the notebook content in this section, the previously exported code will be duplicate as they are being exported to the same file. Usually, one notebook will generate one exported module.\n\nNotebook Content\n\n\nExported source\nfrom fastai.vision.all import *\n\n\nFor this task, we will use the Oxford-IIIT Pet Dataset that contains images of cats and dogs of 37 different breeds. We will first show how to build a simple cat-vs-dog classifier, then a little bit more advanced model that can classify all breeds.\nThe dataset can be downloaded and decompressed with this line of code:\n\npath = untar_data(URLs.PETS)\n\nIt will only do this download once, and return the location of the decompressed archive. We can check what is inside with the .ls() method.\nWe will ignore the annotations folder for now, and focus on the images one. get_image_files is a fastai function that helps us grab all the image files (recursively) in one folder.\n\nfiles = get_image_files(path/\"images\")\nlen(files)\n\n7390\n\n\nTo label our data for the cats vs dogs problem, we need to know which filenames are of dog pictures and which ones are of cat pictures. There is an easy way to distinguish: the name of the file begins with a capital for cats, and a lowercased letter for dogs.\nWe can then define an easy label function:\n\ndef label_func(f): return f[0].isupper()\n\nTo get our data ready for a model, we need to put it in a DataLoaders object. Here we have a function that labels using the file names, so we will use ImageDataLoaders.from_name_func. There are other factory methods of ImageDataLoaders that could be more suitable for your problem, so make sure to check them all in vision.data.dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))\n\ndls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))\n\nWe have passed to this function the directory we’re working in, the files we grabbed, our label_func and one last piece as item_tfms: this is a Transform applied on all items of our dataset that will resize each image to 224 by 224, by using a random crop on the largest dimension to make it a square, then resizing to 224 by 224. If we didn’t pass this, we would get an error later as it would be impossible to batch the items together.\nWe can then check if everything looks okay with the show_batch method (True is for cat, False is for dog):\n\ndls.show_batch()\n\n\n\n\n\n\n\n\nThen we can create a Learner, which is a fastai object that combines the data and a model for training, and uses transfer learning to fine tune a pretrained model in just two lines of code:\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.150823\n0.023608\n0.009472\n00:23\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.053443\n0.007796\n0.002706\n00:29\n\n\n\n\n\nThe first line downloaded a model called ResNet34, pretrained on ImageNet, and adapted it to our specific problem. It then fine tuned that model and in a relatively short time, we get a model with an error rate of well under 1%… amazing!\nIf you want to make a prediction on a new image, you can use learn.predict:\n\nlearn.predict(files[0])\n\n\n\n\n\n\n\n\n('False', tensor(0), tensor([9.9995e-01, 5.1299e-05]))\n\n\nThe predict method returns three things: the decoded prediction (here False for dog), the index of the predicted class and the tensor of probabilities of all classes in the order of their indexed labels(in this case, the model is quite confident about the being that of a dog). This method accepts a filename, a PIL image or a tensor directly in this case. We can also have a look at some predictions with the show_results method:\n\nlearn.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom this, we can build a classifer for images of cats and dogs:\n\nsource\n\n\nCatOrDogImageClassifier\n\n CatOrDogImageClassifier (arch=&lt;function resnet34&gt;, metrics=&lt;function\n                          error_rate&gt;)\n\nClassifier between cat and dog images\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\narch\nfunction\nresnet34\nPretrained model architecture\n\n\nmetrics\nfunction\nerror_rate\nMetrics to be used\n\n\n\n\nsource\n\n\nCatOrDogImageClassifier.predict\n\n CatOrDogImageClassifier.predict (file_path:str)\n\nPredict a single image with the learner",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "workflow.html#tips",
    "href": "workflow.html#tips",
    "title": "Workflow",
    "section": "Tips",
    "text": "Tips\n\nModule Packaging: Each notebook will only export 1 module (or .py file), which is defined by directive #| default_exp &lt;file_name&gt;. However, it is possible to create sub-module with this directive. For instance, if the file_name is defined as classifier.dog_and_cat, then the created module will be exported to file classifier/dog_and_cat.py and a new directory classifier is automatically created in your main module directory.\n\nNotebook Packaging: Each notebook will be automatically rendered into a Quarto Page. The order of the notebook is automatically inferred from the title (complying with naming convention: 01_notebook1.ipynb, 02_notebook2.ipynb. It is also possible to create sections in Quarto Pages by creating a new child directory in the nbs folder with the section name and adding corresponding notebooks to it. It is also possible to customize content structure by editing the sidebar.yml file.\n\nJupyter Lab Support: As we are creating module, it can be beneficial to have type hinting and code styling. Check https://chatgpt.com/share/67120f9f-6c58-8002-b10f-7c18d051d2f0 for how to enable such utilities, as well as customizing them for your own environment.",
    "crumbs": [
      "Workflow"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()",
    "crumbs": [
      "core"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "nbdev-test",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "nbdev-test"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "nbdev-test",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall nbdev_test in Development mode\n# make sure nbdev_test package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to nbdev_test\n$ nbdev_prepare",
    "crumbs": [
      "nbdev-test"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "nbdev-test",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/ninjalabo/nbdev-test.git\nor from conda\n$ conda install -c ninjalabo nbdev_test\nor from pypi\n$ pip install nbdev_test\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages. Additionally you can find package manager specific guidelines on conda and pypi respectively.",
    "crumbs": [
      "nbdev-test"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "nbdev-test",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2",
    "crumbs": [
      "nbdev-test"
    ]
  }
]